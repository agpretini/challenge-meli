# MercadoLibre Challenge â€“ ClasificaciÃ³n de CondiciÃ³n del Producto  
**PredicciÃ³n de productos Nuevos vs Usados**

## ğŸ“Œ Objetivo
El objetivo de este proyecto es construir un pipeline de *machine learning* robusto y reproducible que permita predecir si un producto publicado en MercadoLibre es **nuevo o usado**, a partir de informaciÃ³n del aviso, del vendedor, del producto y *features* derivadas.

La soluciÃ³n pone foco en:
- Calidad de datos y prevenciÃ³n de *data leakage*
- Feature engineering sÃ³lido
- ComparaciÃ³n y optimizaciÃ³n de modelos
- Modularidad y reproducibilidad

---

## ğŸ§  VisiÃ³n General del Proyecto

El proyecto se organiza en un **pipeline en tres etapas**:

1. **ConstrucciÃ³n del dataset** a partir de datos crudos (formato JSON) 
2. **Pipeline de Feature Engineering**  
3. **Entrenamiento, evaluaciÃ³n e inferencia del modelo final**

Cada etapa estÃ¡ implementada como un **script ejecutable independiente**, priorizando claridad, facilidad de debugging y control total del flujo.

---

## ğŸ“ Estructura del proyecto

```text
MeLi_challenge/
â”‚
â”œâ”€â”€ .venv/                       # Virtual environment del proyecto
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                     # Dataset original (jsonlines)
â”‚   â”œâ”€â”€ processed/               # Datasets base y datasets con Feature Engineering
â”‚   â””â”€â”€ artifacts/               # Modelos entrenados, logs, mÃ©tricas y grÃ¡ficos
â”‚
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_process/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ read_utils.py        # Aqui se incluye la funciÃ³n provista en el enunciado para parsear JSONs
â”‚   â”‚   â””â”€â”€ build_dataset.py     # Orquesta la transformaciÃ³n de JSONs a DataFrame
â”‚   â”‚
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ feat_eng_utils.py    # Define transformers y encoders
â”‚   â”‚   â””â”€â”€ feat_eng_pipeline.py # Orquesta el proceso de Feature Engineering
â”‚   â”‚
â”‚   â”œâ”€â”€ experiments/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â”œâ”€â”€ model_experiments_cv.py  # ComparaciÃ³n de modelos base (RF, LGBM, XGB, CatBoost)
â”‚   â”‚   â”œâ”€â”€ xgb_optimize_hp.py       # OptimizaciÃ³n de hiperparÃ¡metros con Optuna
â”‚   â”‚   â””â”€â”€ xgb_select_thesshold.py  # SelecciÃ³n del punto de corte Ã³ptimo
â”‚   â”‚
â”‚   â”œâ”€â”€ model/
â”‚   â”‚   â”œâ”€â”€ __init__.py
â”‚   â”‚   â””â”€â”€ train_infer_pipeline.py  # Entrenamiento final e inferencia sobre test
â”‚
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 01_eda.ipynb             # AnÃ¡lisis Exploratorio de Datos (EDA)
â”‚
â”œâ”€â”€ requirements.txt             # Dependencias del proyecto
â””â”€â”€ README.md                    # DocumentaciÃ³n principal
```

---

## ğŸ“Š AnÃ¡lisis Exploratorio de Datos (EDA)

El EDA se realizÃ³ con los siguientes objetivos:
- Comprender la estructura y calidad de los datos
- Detectar variables relevantes con poder predictivo
- Guiar decisiones de *feature engineering*

### Principales hallazgos:
- Variables con **mÃ¡s del 80% de valores nulos** fueron eliminadas
- Algunas variables (ej. `warranty`) mostraron buena relaciÃ³n con el target pese a tener alta tasa de nulos
- Gran parte de las variables son **categÃ³ricas**, muchas con **altÃ­sima cardinalidad**
- Se identificaron columnas que contienen **listas o diccionarios**, requiriendo procesamiento especÃ­fico
- La mayorÃ­a de las variables numÃ©ricas presentan **distribuciones altamente sesgadas**, por lo que se aplicaron transformaciones logarÃ­tmicas
- Se detectaron columnas con **varianza nula o casi nula**, que fueron eliminadas por no aportar informaciÃ³n predictiva

---

## ğŸ§± Feature Engineering

Se desarrollÃ³ un `FeatureEngineeringPipeline` propio con las siguientes caracterÃ­sticas:

- NormalizaciÃ³n de tipos (categÃ³ricas, booleanas, timestamps)
- ImputaciÃ³n de nulos:
  - Mediana para variables numÃ©ricas
  - Moda para categÃ³ricas y booleanas
- GeneraciÃ³n de features a partir de:
  - Tags
  - ImÃ¡genes
  - TÃ­tulos
  - Variables temporales
  - Ratios y transformaciones numÃ©ricas
- Estrategias de encoding:
  - One-Hot Encoding (cardinalidad baja)
  - Frequency Encoding (cardinalidad alta sin relaciÃ³n muy diferente con el target entre sus categorÃ­as)
  - Target Encoding (cardinalidad alta mostrando relaciÃ³n muy diferente con el target entre sus categorÃ­as)
- Estricto control de *data leakage*:
  - El pipeline se **fitea solo con datos de train**
  - Los folds de validaciÃ³n se transforman sin refit

El pipeline es reutilizable en:
- Cross-validation
- OptimizaciÃ³n de hiperparÃ¡metros
- Entrenamiento final productivo

---

## ğŸ¤– SelecciÃ³n y EvaluaciÃ³n de Modelos

Se evaluaron los siguientes algoritmos usando **Stratified K-Fold Cross Validation**:

- Random Forest
- LightGBM
- CatBoost
- XGBoost

### MÃ©tricas evaluadas:
- **Accuracy** (restricciÃ³n principal)
- **ROC-AUC** (mÃ©trica secundaria de optimizaciÃ³n)
- **Recall de la clase â€œusedâ€** (crÃ­tica para el negocio)
- **Precision de la clase â€œusedâ€**

### Criterio de selecciÃ³n:
- Accuracy â‰¥ **0.86**
- MÃ¡ximo ROC-AUC
- Buen balance entre recall y precision de usados

â¡ï¸ **XGBoost** resultÃ³ el mejor modelo en tÃ©rminos de performance global y estabilidad.

---

## ğŸ” OptimizaciÃ³n de HiperparÃ¡metros

La optimizaciÃ³n se realizÃ³ con **Optuna**, utilizando:

- 4 folds de CV por trial
- Objetivo: maximizar **ROC-AUC promedio**
- RestricciÃ³n: descartar trials con accuracy < 0.86
- 20 trials
  
Los resultados fueron logueados y exportados para trazabilidad completa.

---

## ğŸ¯ OptimizaciÃ³n del Punto de Corte

Una vez entrenado el modelo final:
- Se optimizÃ³ el **threshold de decisiÃ³n**
- Objetivo: maximizar el recall de productos usados
- RestricciÃ³n: mantener accuracy â‰¥ 0.86

Esto permite priorizar la detecciÃ³n de productos usados sin degradar la calidad global del modelo.

---

## ğŸš€ EjecuciÃ³n del Pipeline Final

### Paso 1 â€“ ConstrucciÃ³n del dataset
```bash
python src/data_process/build_dataset.py
```
### Paso 2 â€“ Feature Engineering
```bash
python src/features/feat_eng_pipeline.py
```

### Paso 3 â€“ ConstrucciÃ³n del dataset
```bash
python src/model/train_infer_pipeline.py
```

## Resultados sobre el set de Test
- Accuracy: 0.865 --> superando el umbral requerido de 0.86
- ROC-AUC: 0.9465 --> indicando una excelente capacidad del modelo para discriminar las clases
- Recall: 0.9234 --> capturando la mayoria de los productos usados
- Precision: 0.8095 --> reflejando predicciones de calidad



