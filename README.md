# MercadoLibre Challenge ‚Äì Clasificaci√≥n de Condici√≥n del Producto  
**Predicci√≥n de productos Nuevos vs Usados**

## üìå Objetivo
El objetivo de este proyecto es construir un pipeline de *machine learning* robusto y reproducible que permita predecir si un producto publicado en MercadoLibre es **nuevo o usado**, a partir de informaci√≥n estructurada del aviso y *features* derivadas.

La soluci√≥n pone foco en:
- Calidad de datos y prevenci√≥n de *data leakage*
- Feature engineering s√≥lido
- Comparaci√≥n y optimizaci√≥n de modelos
- Modularidad y reproducibilidad

---

## üß† Visi√≥n General del Proyecto

El proyecto se organiza en un **pipeline offline en tres etapas**:

1. **Construcci√≥n del dataset** a partir de datos crudos  
2. **Pipeline de Feature Engineering**  
3. **Entrenamiento, evaluaci√≥n e inferencia del modelo final**

Cada etapa est√° implementada como un **script ejecutable independiente**, priorizando claridad, facilidad de debugging y control total del flujo.

---

## üìÇ Estructura del Repositorio



---

## üìä An√°lisis Exploratorio de Datos (EDA)

El EDA se realiz√≥ con los siguientes objetivos:
- Comprender la estructura y calidad de los datos
- Detectar variables relevantes con poder predictivo
- Guiar decisiones de *feature engineering*

### Principales hallazgos:
- Variables con **m√°s del 90% de valores nulos** fueron eliminadas
- Algunas variables (ej. `warranty`) mostraron buena relaci√≥n con el target pese a tener alta tasa de nulos
- Gran parte de las variables son **categ√≥ricas**, muchas con **alt√≠sima cardinalidad**
- Se identificaron columnas que contienen **listas o diccionarios**, requiriendo procesamiento espec√≠fico
- La mayor√≠a de las variables num√©ricas presentan **distribuciones altamente sesgadas**, por lo que se aplicaron transformaciones logar√≠tmicas
- Se detectaron columnas con **varianza nula o casi nula**, que fueron eliminadas por no aportar informaci√≥n predictiva

---

## üß± Feature Engineering

Se desarroll√≥ un `FeatureEngineeringPipeline` propio con las siguientes caracter√≠sticas:

- Normalizaci√≥n de tipos (categ√≥ricas, booleanas, timestamps)
- Imputaci√≥n de nulos:
  - Mediana para variables num√©ricas
  - Moda para categ√≥ricas y booleanas
- Generaci√≥n de features a partir de:
  - Tags
  - Im√°genes
  - Variables temporales
  - Ratios y transformaciones num√©ricas
- Estrategias de encoding:
  - One-Hot Encoding
  - Frequency Encoding
  - Target Encoding
- Estricto control de *data leakage*:
  - El pipeline se **fitea solo con datos de train**
  - Los folds de validaci√≥n se transforman sin refit

El pipeline es reutilizable en:
- Cross-validation
- Optimizaci√≥n de hiperpar√°metros
- Entrenamiento final productivo

---

## ü§ñ Selecci√≥n y Evaluaci√≥n de Modelos

Se evaluaron los siguientes algoritmos usando **Stratified K-Fold Cross Validation**:

- Random Forest
- LightGBM
- CatBoost
- XGBoost

### M√©tricas evaluadas:
- **Accuracy** (restricci√≥n principal)
- **ROC-AUC** (m√©trica secundaria de optimizaci√≥n)
- **Recall de la clase ‚Äúused‚Äù** (cr√≠tica para el negocio)
- **Precision de la clase ‚Äúused‚Äù**

### Criterio de selecci√≥n:
- Accuracy ‚â• **0.86**
- M√°ximo ROC-AUC
- Buen balance entre recall y precision de usados

‚û°Ô∏è **XGBoost** result√≥ el mejor modelo en t√©rminos de performance global y estabilidad.

---

## üîé Optimizaci√≥n de Hiperpar√°metros

La optimizaci√≥n se realiz√≥ con **Optuna**, utilizando:

- 4 folds de CV por trial
- Objetivo: maximizar **ROC-AUC promedio**
- Restricci√≥n: descartar trials con accuracy < 0.86
- 20 trials
- Ajuste expl√≠cito de `scale_pos_weight` para tratar el desbalance de clases

Los resultados fueron logueados y exportados para trazabilidad completa.

---

## üéØ Optimizaci√≥n del Punto de Corte

Una vez entrenado el modelo final:
- Se optimiz√≥ el **threshold de decisi√≥n**
- Objetivo: maximizar el recall de productos usados
- Restricci√≥n: mantener accuracy ‚â• 0.86

Esto permite priorizar la detecci√≥n de productos usados sin degradar la calidad global del modelo.

---

## üöÄ Ejecuci√≥n del Pipeline Final

### Paso 1 ‚Äì Construcci√≥n del dataset
```bash
python src/data_process/build_dataset.py

### Paso 2 ‚Äì Feature Engineering
```bash
python src/features/feat_eng_pipeline.py

### Paso 3 ‚Äì Construcci√≥n del dataset
```bash
python src/model/train_infer_pipeline.py




